{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose of this notebook: \n",
    "* compute the offsets from the different summary stat methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.auto_scroll_threshold = 9999;"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.auto_scroll_threshold = 9999;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "%matplotlib inline \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "plt.rcParams['figure.figsize'] = (10, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import extract_catalog as ec\n",
    "import get_DM_centroids as getDM\n",
    "# import seaborn as sns\n",
    "import compute_distance as compDist\n",
    "import plot_cred_int as plotCI\n",
    "import get_KDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = \"../../data/test_results/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read in files "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "want to read in the second half of the projections for the DM data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clstNo = 43\n",
    "date_stamp = '06_21_16'\n",
    "\n",
    "DM_fhats = \\\n",
    "    h5py.File(data_path +\n",
    "              \"DM_fhat_clst{0}_{1}.h5\".format(\n",
    "            clstNo, date_stamp), 'r')\n",
    "star_fhats = \\\n",
    "    h5py.File(data_path +\n",
    "              \"stars_fhat_clst{0}_{1}.h5\".format(\n",
    "            clstNo, date_stamp), 'r')\n",
    "main_FOF_h5 = h5py.File(\n",
    "        \"../../data/\" +\n",
    "        \"Illustris-1_fof_subhalo_myCompleteHaloCatalog_00135\" +\n",
    "        \".hdf5\", \"r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# figure out how many projections we did "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clstNo = [int(no) for no in star_fhats.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "star_paths = compDist.retrieve_cluster_path(star_fhats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the list of `DM_paths` are "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The projections do not mean a thing except for debugging purposes, \n",
    "only the `clstNo` is a valid identifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "split_path = star_paths[0].split('/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fixed_path = '/'.join(split_path[1:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = '0' + '/' + fixed_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "projections = star_fhats[str(clstNo[0]) + '/' + fixed_path].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## columns in my uber dataframe (projection independent part)\n",
    "| ClstNo | $m_{200c}$ | richness | relaxedness0| relaxedness1 |  \n",
    "\n",
    "\n",
    "## projection dependent part \n",
    "| ClstNo | kernel_width | $\\Delta s_{BCG}$ | $\\Delta s_{KDE}$ | $\\zeta$ | $\\Delta s_{SA}$ | $\\Delta s_{C}$ |  projection | total_peaks_dens | \n",
    "\n",
    "ClstNo is retained to match and join the two sets of `df`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gather the projection dependent part of the `uber_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "summary_stat_keys = ['BCG', 'centroid', \"shrink_cent\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_list = []\n",
    "for star_path in star_paths: \n",
    "    clstNo = [int(star_path.split('/')[0])]\n",
    "    star_fhat = star_fhats[star_path]\n",
    "    for bin_width in ['/0.0/', '/25.0/']:\n",
    "        DM_fhat = DM_fhats[star_path + bin_width]\n",
    "    \n",
    "        # temporarily put results in matched_stat first\n",
    "        matched_stat = \\\n",
    "            compDist.compute_distance_between_DM_and_gal_peaks(\n",
    "                star_fhat, DM_fhat, compute_2D_distance=True\n",
    "            )        \n",
    "            \n",
    "        # compute all other offsets before putting them somewhere \n",
    "        # for computing my uber_df\n",
    "        dist_dict = compDist.compute_distance_for_other_peaks(\n",
    "            matched_stat, star_fhat, summary_stat_keys=summary_stat_keys,\n",
    "            compute_2D_distance=True\n",
    "        )\n",
    "        peak_no = len(matched_stat['dist'])\n",
    "        if peak_no > 1:\n",
    "            df = pd.DataFrame(dist_dict, \n",
    "                              index=[clstNo[0] for i in range(peak_no)])\n",
    "            df['peak_id'] = range(peak_no)\n",
    "            df['KDE' ] = matched_stat['dist']\n",
    "            df['Delta_x_KDE' ] = matched_stat['Delta_x_KDE']\n",
    "            df['Delta_y_KDE' ] = matched_stat['Delta_y_KDE']\n",
    "            \n",
    "        else:\n",
    "            df = pd.DataFrame(dist_dict, index=clstNo)\n",
    "            df['peak_id'] = 0.\n",
    "            df['KDE'] = matched_stat['dist'][:1]\n",
    "            df['Delta_x_KDE' ] = matched_stat['Delta_x_KDE'][:1]\n",
    "            df['Delta_y_KDE' ] = matched_stat['Delta_y_KDE'][:1]\n",
    "            \n",
    "        df['total_peaks_dens'] = np.sum(star_fhat['peaks_dens'])\n",
    "        df['bin_width'] = float(bin_width[1:-1])    \n",
    "        df_list.append(df)\n",
    "\n",
    "uber_df_proj = pd.concat(df_list)\n",
    "uber_df_proj.to_hdf('../../data/uber_df_{0}.h5'.format(date_stamp), \n",
    "                    'df')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
